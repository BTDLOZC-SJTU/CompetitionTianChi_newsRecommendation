{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4236,
     "status": "ok",
     "timestamp": 1608302449256,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "QV7Kcegk0HQY",
    "outputId": "d6497a63-333d-498c-b3df-17b487ee089e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepmatch\n",
      "  Downloading https://files.pythonhosted.org/packages/e4/ae/6fec2e57b922ce8832653278bc9bd7a3d844d725f3c2b7c3cd544cba1a90/deepmatch-0.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from deepmatch) (2.10.0)\n",
      "Collecting deepctr==0.8.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/61/fb1c7f06f0fed2be82068f365824532afcf0bbed77e85cdb4107196ea0bf/deepctr-0.8.2-py3-none-any.whl (110kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 14.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from deepmatch) (2.23.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->deepmatch) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py->deepmatch) (1.19.4)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->deepmatch) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->deepmatch) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->deepmatch) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->deepmatch) (2.10)\n",
      "Installing collected packages: deepctr, deepmatch\n",
      "Successfully installed deepctr-0.8.2 deepmatch-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install deepmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13961,
     "status": "ok",
     "timestamp": 1608302458988,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "_EiMeqSXEw8U",
    "outputId": "1eebeede-aa50-41fc-cd70-3ea42136c1a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-gpu\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/32/8b29e3f99224f24716257e78724a02674761e034e6920b4278cc21d19f77/faiss_gpu-1.6.5-cp36-cp36m-manylinux2014_x86_64.whl (67.6MB)\n",
      "\u001b[K     |████████████████████████████████| 67.7MB 56kB/s \n",
      "\u001b[?25hInstalling collected packages: faiss-gpu\n",
      "Successfully installed faiss-gpu-1.6.5\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137725,
     "status": "ok",
     "timestamp": 1608302582758,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "KIaTsLMz0OMm",
    "outputId": "4e08140a-e891-48ae-eea3-cdf260b6b39f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'machine learning', 'TIANCHI04', 'N05', 'out']"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "path = \"/content/drive/My Drive\"\n",
    "\n",
    "os.chdir(path)\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 137724,
     "status": "ok",
     "timestamp": 1608302582759,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "DIE1SFKDz7b-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import math\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 139043,
     "status": "ok",
     "timestamp": 1608302584080,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "dfQSuozHz7cE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from tqdm import tqdm  \n",
    "from collections import defaultdict  \n",
    "import os, math, warnings, math, pickle\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import faiss\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from deepmatch.models import *\n",
    "from deepmatch.utils import sampledsoftmaxloss\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 139041,
     "status": "ok",
     "timestamp": 1608302584080,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "4vDTNDAkmuI6"
   },
   "outputs": [],
   "source": [
    "# 节省数据内存\n",
    "article_dtypes = {\n",
    "    \"article_id\": \"int32\",\n",
    "    \"category_id\": \"int16\",\n",
    "    \"created_at_ts\": \"int64\",\n",
    "    \"words_count\": \"int16\"}\n",
    "\n",
    "click_log_dtypes = {\n",
    "    \"user_id\": \"int32\",\n",
    "    \"click_article_id\": \"int32\",\n",
    "    \"click_timestamp\": \"int64\",\n",
    "    \"click_environment\": \"int8\",\n",
    "    \"click_deviceGroup\": \"int8\",\n",
    "    \"click_os\": \"int8\",\n",
    "    \"click_country\": \"int8\",\n",
    "    \"click_region\": \"int8\",\n",
    "    \"click_referrer_type\": \"int8\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 139041,
     "status": "ok",
     "timestamp": 1608302584081,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "dnaYC1PW1Pyp"
   },
   "outputs": [],
   "source": [
    "def get_train_click_df(data_save_path, name='train_click_log.csv'):\n",
    "    \"\"\"获取训练样本\"\"\"\n",
    "    train_df = pd.read_csv(data_save_path + name, dtype=click_log_dtypes)\n",
    "    return train_df\n",
    "\n",
    "def get_test_click_df(data_save_path, name='testA_click_log.csv'):\n",
    "    \"\"\"获取测试样本\"\"\"\n",
    "    test_df = pd.read_csv(data_save_path + name, dtype=click_log_dtypes)\n",
    "    return test_df\n",
    "\n",
    "def get_item_info_df(data_save_path, name='articles.csv'):\n",
    "    \"\"\"获取文章特征\"\"\"\n",
    "    item_info_df = pd.read_csv(data_save_path + name,  dtype=article_dtypes)\n",
    "    item_info_df = item_info_df.rename(columns={'article_id': 'click_article_id'})\n",
    "    return item_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 139040,
     "status": "ok",
     "timestamp": 1608302584082,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "IFChQ1gHz7cF"
   },
   "outputs": [],
   "source": [
    "data_path = \"N05/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 141306,
     "status": "ok",
     "timestamp": 1608302586350,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "mu0YHaFSnDKn"
   },
   "outputs": [],
   "source": [
    "trn_df = get_train_click_df(data_path, \"offline_trn_df.csv\")\n",
    "val_df = get_test_click_df(data_path, \"offline_val_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 142522,
     "status": "ok",
     "timestamp": 1608302587568,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "aB9x-x4Oz7cF"
   },
   "outputs": [],
   "source": [
    "sample_df = trn_df.append(val_df)\n",
    "item_info_df = get_item_info_df(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 142521,
     "status": "ok",
     "timestamp": 1608302587568,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "eE2fpJx_22Kl"
   },
   "outputs": [],
   "source": [
    "user_profile_ = sample_df[[\"user_id\"]].drop_duplicates('user_id')\n",
    "item_profile_ = sample_df[[\"click_article_id\"]].drop_duplicates('click_article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 142521,
     "status": "ok",
     "timestamp": 1608302587570,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "NdlHEizMz7cF"
   },
   "outputs": [],
   "source": [
    "user_features = [\"user_id\", \"click_article_id\"]\n",
    "feature_max_idx = {}\n",
    "for feature in user_features:\n",
    "    lbe = LabelEncoder()\n",
    "    sample_df[feature] = lbe.fit_transform(sample_df[feature]) + 1\n",
    "    feature_max_idx[feature] = sample_df[feature].max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 143499,
     "status": "ok",
     "timestamp": 1608302588549,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "WLtcVjqzz7cG"
   },
   "outputs": [],
   "source": [
    "user_profile = sample_df[[\"user_id\"]].drop_duplicates('user_id')\n",
    "item_profile = sample_df[[\"click_article_id\"]].drop_duplicates('click_article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 143498,
     "status": "ok",
     "timestamp": 1608302588550,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "p9Mn2o5d3U-F"
   },
   "outputs": [],
   "source": [
    "user_index_2_rawid = dict(zip(user_profile['user_id'], user_profile_['user_id']))\n",
    "item_index_2_rawid = dict(zip(item_profile['click_article_id'], item_profile_['click_article_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 143501,
     "status": "ok",
     "timestamp": 1608302588554,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "ILEIJXwBz7cH"
   },
   "outputs": [],
   "source": [
    "user_profile.set_index(\"user_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 143501,
     "status": "ok",
     "timestamp": 1608302588555,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "baBvBP_hz7cH"
   },
   "outputs": [],
   "source": [
    "# 获取双塔召回时的训练验证数据\n",
    "# negsample指的是通过滑窗构建样本的时候，负样本的数量\n",
    "def gen_data_set(click_df, negsample=0):\n",
    "    click_df.sort_values(\"click_timestamp\", inplace=True)\n",
    "    item_ids = click_df[\"click_article_id\"].unique()\n",
    "    \n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    for reviewerId, hist in tqdm(click_df.groupby('user_id')):\n",
    "\n",
    "        pos_list = hist[\"click_article_id\"].tolist()\n",
    "        \n",
    "        if negsample > 0:\n",
    "            neg_candidate_set = list(set(item_ids) - set(pos_list)) # 用户没看过的文章里面选择负样本\n",
    "            neg_list = np.random.choice(neg_candidate_set, size=len(pos_list)*negsample, replace=True) # 对于每个正样本，选择n个负样本\n",
    "    \n",
    "        # 长度只有一个的时候，需要把这条数据也放到训练集中，不然的话最终学到的embedding就会有缺失\n",
    "        if len(pos_list) == 1:\n",
    "            train_set.append((reviewerId, [], pos_list[0], 1, len(pos_list)))\n",
    "            test_set.append((reviewerId, [], pos_list[0], 1, len(pos_list)))\n",
    "            \n",
    "        # 滑窗构造正负样本\n",
    "        for i in range(1, len(pos_list)):\n",
    "            \n",
    "            hist = pos_list[:i]\n",
    "            if i != len(pos_list) - 1: \n",
    "                train_set.append((reviewerId, hist[::-1], pos_list[i], 1, len(hist[::-1])))\n",
    "                for negi in range(negsample):\n",
    "                    train_set.append((reviewerId, hist[::-1], neg_list[i*negsample+negi], 0, len(hist[::-1]))) # 负样本 [user_id, his_item, neg_item, label, len(his_item)]\n",
    "            else:\n",
    "                # 将最长的那一个序列长度作为测试数据\n",
    "                train_set.append((reviewerId, hist[::-1], pos_list[i], 1, len(hist[::-1])))\n",
    "                test_set.append((reviewerId, hist[::-1], pos_list[i], 1, len(hist[::-1])))\n",
    "                \n",
    "    random.shuffle(train_set)\n",
    "    random.shuffle(test_set)\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 143499,
     "status": "ok",
     "timestamp": 1608302588555,
     "user": {
      "displayName": "Chi Zhang",
      "photoUrl": "",
      "userId": "06196948196766276684"
     },
     "user_tz": -480
    },
    "id": "KduRloWCz7cI"
   },
   "outputs": [],
   "source": [
    "# 将输入的数据进行padding，使得序列特征的长度都一致\n",
    "def gen_model_input(train_set, user_profile, seq_max_len):\n",
    "\n",
    "    train_uid = np.array([line[0] for line in train_set])\n",
    "    train_seq = [line[1] for line in train_set]\n",
    "    train_iid = np.array([line[2] for line in train_set])\n",
    "    train_label = np.array([line[2] for line in train_set])\n",
    "    train_hist_len = np.array([line[4] for line in train_set])\n",
    "\n",
    "    train_seq_pad = pad_sequences(train_seq, maxlen=seq_max_len, padding='post', truncating='post', value=0)\n",
    "    train_model_input = {\"user_id\": train_uid, \"click_article_id\": train_iid, \"hist_article_id\": train_seq_pad,\n",
    "                         \"hist_len\": train_hist_len}\n",
    "    \n",
    "    for key in [\"click_environment\", \"click_deviceGroup\", \"click_os\", \"click_country\",\"click_region\",\"click_referrer_type\"]:\n",
    "        train_model_input[key] = user_profile.loc[train_model_input['user_id']][key].values\n",
    "        \n",
    "    return train_model_input, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "DwYt1bOEz7cI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [24:39<00:00, 135.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = gen_data_set(sample_df, 1)\n",
    "pickle.dump(train_set, open('train_set_0.pkl', 'wb'))\n",
    "pickle.dump(test_set, open('test_set_0.pkl', 'wb'))\n",
    "#train_set = pickle.load(open('train_set.pkl', 'rb'))\n",
    "#test_set = pickle.load(open('test_set.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8987EMQ6z7cI"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 100\n",
    "train_model_input, train_label = gen_model_input(train_set, user_profile, SEQ_LEN)\n",
    "test_model_input, test_label = gen_model_input(test_set, user_profile, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZafVYDlwz7cI"
   },
   "outputs": [],
   "source": [
    "# 2.count #unique features for each sparse field and generate feature config for sequence feature\n",
    "\n",
    "embedding_dim = 32\n",
    "\n",
    "# SparseFeat(name, vocabulary_size, embedding_dim)\n",
    "# VarLenSparseFeat(SparseFeat(), SEQ_LEN, 'mean', 'hist_len'),  序列特征\n",
    "user_feature_columns = [SparseFeat('user_id', feature_max_idx['user_id'], 16),\n",
    "                        SparseFeat(\"click_environment\", feature_max_idx['click_environment'], 16),\n",
    "                        SparseFeat(\"click_deviceGroup\", feature_max_idx['click_deviceGroup'], 16),\n",
    "                        SparseFeat(\"click_os\", feature_max_idx['click_os'], 16),\n",
    "                        SparseFeat(\"click_country\", feature_max_idx['click_country'], 16),\n",
    "                        SparseFeat(\"click_region\", feature_max_idx['click_region'], 16),\n",
    "                        SparseFeat(\"click_referrer_type\", feature_max_idx['click_referrer_type'], 16),\n",
    "                        VarLenSparseFeat(SparseFeat('hist_article_id', feature_max_idx['click_article_id'], embedding_dim,\n",
    "                                                    embedding_name=\"click_article_id\"), SEQ_LEN, 'mean', 'hist_len'),]\n",
    "\n",
    "item_feature_columns = [SparseFeat('click_article_id', feature_max_idx['click_article_id'], embedding_dim),]\n",
    "\"\"\"\"\"\"\n",
    "# 3.Define Model and train\n",
    "\n",
    "K.set_learning_phase(True)\n",
    "\n",
    "import tensorflow as tf\n",
    "if tf.__version__ >= '2.0.0':\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "#model = YoutubeDNN(user_feature_columns, item_feature_columns, num_sampled=100, user_dnn_hidden_units=(128, 64, embedding_dim))\n",
    "model = MIND(user_feature_columns,item_feature_columns,dynamic_k=False,p=1,k_max=5,num_sampled=100,user_dnn_hidden_units=(128,64, embedding_dim))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=sampledsoftmaxloss)  # \"binary_crossentropy\")\n",
    "\n",
    "history = model.fit(train_model_input, train_label,  # train_label,\n",
    "                    batch_size=512, epochs=30, verbose=1, validation_split=0.0, )\n",
    "model.save(\"N05/model/ytb_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIWrrTrkz7cJ"
   },
   "outputs": [],
   "source": [
    "# 4. Generate user features for testing and full item features for retrieval\n",
    "test_user_model_input = test_model_input\n",
    "all_item_model_input = {\"click_article_id\": item_profile['click_article_id'].values,}\n",
    "\n",
    "user_embedding_model = Model(inputs=model.user_input, outputs=model.user_embedding)\n",
    "item_embedding_model = Model(inputs=model.item_input, outputs=model.item_embedding)\n",
    "\n",
    "#user_embs = user_embedding_model.predict(test_user_model_input, batch_size=2 ** 12)\n",
    "user_embs = user_embs[:, 5, :]  # i in [0,k_max) if MIND\n",
    "item_embs = item_embedding_model.predict(all_item_model_input, batch_size=2 ** 12)\n",
    "\n",
    "print(user_embs.shape)\n",
    "print(item_embs.shape)\n",
    "pickle.dump(user_embs, open('N05/FE/offline_user_embs.pkl', 'wb'))\n",
    "pickle.dump(item_embs, open('N05/FE/offline_item_embs.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQG94LUpLBdy"
   },
   "outputs": [],
   "source": [
    "submit_df = pd.read_csv(\"N05/data/sample_submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xbb2ZQhfPGYh"
   },
   "outputs": [],
   "source": [
    "test_true_label = {line[0]:[line[2]] for line in test_set}\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from deepmatch.utils import recall_N\n",
    "\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "# faiss.normalize_L2(item_embs)\n",
    "index.add(item_embs)\n",
    "# faiss.normalize_L2(user_embs)\n",
    "D, I = index.search(np.ascontiguousarray(user_embs), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44JgA5lML65p"
   },
   "outputs": [],
   "source": [
    "s = []\n",
    "hit = 0\n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "for i, uid in tqdm(enumerate(test_user_model_input['user_id'])):\n",
    "    pred = [item_profile['click_article_id'].values[x] for x in I[i]]\n",
    "    truePred = [item_index_2_rawid[p] for p in pred]\n",
    "    for j in range(len(truePred)):\n",
    "        user_recall_items_dict[uid - 1][truePred[j]] = D[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmTrA7ftw_FL"
   },
   "outputs": [],
   "source": [
    "ytb_sort_recall_dict = {}\n",
    "for user_id, item_dict in tqdm(user_recall_items_dict.items()):\n",
    "    ytb_sort_recall_dict[user_id] = list(item_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWXyLNJ73xtc"
   },
   "outputs": [],
   "source": [
    "pickle.dump(ytb_sort_recall_dict, open('N05/recall/ytb_sort_recall_dict.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l45Dzvrk1Kxo"
   },
   "outputs": [],
   "source": [
    "D[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93Qf0JCsOI5n"
   },
   "outputs": [],
   "source": [
    "user_recall_items_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3whGEw8Nz7cL"
   },
   "source": [
    "submit_df = pd.read_csv(\"../data/sample_submit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RW5WVNXdz7cL"
   },
   "source": [
    "youtube_user_recall_items_dict = youtubednn_u2i_dict(sample_df, topk=40)\n",
    "pickle.dump(youtube_user_recall_items_dict, open('youtube_user_recall_items_dict.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "YouTubeDNN.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
