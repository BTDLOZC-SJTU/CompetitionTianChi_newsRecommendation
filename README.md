# CompetitionTianChi_newsRecommendation
天池大赛——新闻推荐场景下的用户行为预测挑战赛，SOLO赛，B榜排名5/5338

# 解决方案
## 召回方案
->使用热度召回、改进itemCF、抽样Swing和item2vec进行多路召回，结合faiss库计算相似文章尝试解决冷启动问题，采用bayes-optimization选取最优超参数，最终每个用户召回50篇候选文章。
### 召回策略1：热度召回
- 普通方案：直接对新闻id做一个value_counts然后返回前5个文章（没有考虑文章的时效性）
- 我的方案：考虑每个用户最后一次点击的时间，返回一个区间内的热门文章，可设置为超参数

主要用于文本补充，当其他样本无法满足召回需求，则用热度召回补充

### 召回策略2：itemCF

i2i_sim物品相似度矩阵计算：
- **考虑文章的正向顺序点击和反向顺序点击**：如果是按照时间戳正向的话权重设为1，反向的话设一个小于1的超参数，因为考虑到网页间的图结构，经常是点完一个后下面有相关推荐，用户很可能点击下一个，反之则基本不会。
- **考虑文章的位置信息权重**：考虑到了随时间的信息衰减，如果两个文章点击的次序距离太远，做一个缩放，0.8**(np.abs(loc2 - loc1) – 1)，也设一个超参数。
- **考虑文章的点击时间权重**：这个是用户对物品的一个行为特征，与位置信息权重的想法类似，用一个指数来进行衰减。
- **考虑文章创建时间的点击权重**：物品本身的特征，与文章点击时间权重的处理方法相似。
- 其他的还考虑了物品之间Embedding向量之间的相似度、物品是否属于同一个类别（这个类别是官方提供的，有400多种，我不是很明白），是的话乘1.1权重，不是就乘1.0、还有文章的字数，这些我尝试过加到相似性计算中，效果不是很好，后来就没加。

itemCF推荐：
- **文章创建时间和用户点击时间差**：强特，每一个用户推荐时，找到最后一次点击时间戳，然后设一个最早可能点击时间和最晚可能点击时间，如果相似文章的创建时间不在这一个区间内，就直接pass。
- **文章创建时间差和相似文章对应文章在用户点击序列中的位置**：离最后一次点击越远的文章，其相似文章的权重就越低。

### 召回策略3：swing

其实一开始我是想用UserCF也计算一下的，因为新闻本身的兴趣点就比较分散，用户更倾向于追求新闻的及时性和热点性，UserCF就能比较好地把握这一点。但实际跑起来的时候内存爆了，没办法用，但还是想把用户彼此之间的信息融入到我的召回模型里。所以找到了阿里的协同过滤推荐算法swing，
Swing的主要思想是基于图结构（u1,u2,i1），用户1和用户2都看过文章1和2，那说明1和2有关联，如果这种三元组数量越多，说明权重越大。
算法：计算两个用户阅读文章的交集，权重分子与之间item相似，分母则对两个用户的交集长度做了一个补充，如果这两个用户交集长度很小，则说明他们的兴趣差异很大，但同时看过这篇文章，说明这两篇文章相似度很高。

但还是爆内存了，这个图结构本质上是三阶特征，本身一二阶特征都够呛了，所以我考虑采样，方法是扔掉历史观看序列很长（大于8）的活跃用户样本，扔掉观看序列较小（小于3）的不活跃用户样本，剩下约63%的样本，然后进行计算。这个想法是我拍脑袋决定的，因为活跃用户和不活跃用户的参考价值都比较小，其实主要目的就是想至少算出来个数，来看看结果，结果还行，有0.18左右的得分。

### 召回策略4：item2vec

将用户的点击序列扔到w2v模型里训练，得到每个新闻的Embedding向量，然后根据用户历史点击的新闻选取最相似的新闻推荐。（item2vec是没有时间窗概念的，认为序列中任意两个物品都相关），但比赛里我还是用的gensim库里的Word2Vec训练器（size: 表示词向量的维度。window：决定了目标词会与多远距离的上下文产生关系。）


### 其他文件测试了UserCF、基于embedding的冷启动方案和基于DNN的召回方案，其中UserCF爆内存了，剩下两个效果下降，故没有放到最终测试中。
## 排序方案
->构建用户行为和文章自身特征，根据召回结果按照1:5划分正负样本转化为CTR预估问题，采用lightGBM进行5折交叉验证，根据输出概率得到文章得分，最终HR@5达到0.27，HR@50达到0.49。
排序的提升很小，关键在于正负样本的划分，使用了3种采样方法：
* 1.采取了滑窗采样的方式，考虑到最多只少只有一个样本候选，所以滑窗的长度设置为1，每一个正样本采1个负样本，这里的负样本是在所有候选集里random.choice的（不过没有去重，与word2vec考虑一致），统计特征后进行训练，效果很差，而且很慢。
* 2.在召回时，不考虑样本是否出现在历史样本里，直接输出，如果召回样本中出现了用户点击过的样本，则标记1，然后每个用户在召回样本里随机采5个负样本，采用的df.sample，总感觉不对，出现时空穿越，不合逻辑。
* 3.对训练集进行二次划分，提取出最后一个点击的文章作为ans，对前面的文章再进行一次召回，如果召回中出现了ans，则标记为1，然后随机采5个（训练数据不完全）。
